{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 14:49:11.474911: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 14:49:11.603091: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 14:49:11.606926: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-03-04 14:49:11.606943: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-03-04 14:49:12.131029: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-04 14:49:12.131060: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-04 14:49:12.131064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/wulab/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow.keras.models import model_from_json, load_model\n",
    "import numpy\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import pyipopt\n",
    "from numpy import *\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################################### Simulation time step ##################################\n",
    "delta = 0.01   # sampling time\n",
    "hc = 1e-4     # integration time step\n",
    "oper_time = 0.01  \n",
    "\n",
    "################################## Initial states #########################################\n",
    "CAi=-1.65\n",
    "Ti=72\n",
    "x1_nn=CAi\n",
    "x2_nn=Ti\n",
    "x1_record=[CAi]\n",
    "x2_record=[Ti]\n",
    "u1_record=[]\n",
    "u2_record=[]\n",
    "\n",
    "##################################### Constants ###########################################\n",
    "a=1060\n",
    "b=22\n",
    "d=0.52  # Lyapunov function V=x^T*P*x\n",
    "\n",
    "# CSTR PARAMETERS\n",
    "F=5\n",
    "V=1\n",
    "k0=8460000\n",
    "E=50000     # parametric drift #####E has the most effect on process dynamics######\n",
    "R=8.314\n",
    "T0=300\n",
    "Dh=-11500\n",
    "rho=1000\n",
    "sigma=1000\n",
    "cp=0.231\n",
    "Qs=0\n",
    "CA0s=4\n",
    "w1_std=2.5  #disturbance std\n",
    "w2_std=70   #disturbance std\n",
    "\n",
    "\n",
    "########################################### steady-state ###################################\n",
    "CAs= 1.9537\n",
    "Ts=  401.8727\n",
    "\n",
    "# state_ss=numpy.array([Ts, CAs])\n",
    "# input_ss=numpy.array([Qs, CA0s])\n",
    "state_ss=numpy.array([CAs,Ts])\n",
    "input_ss=numpy.array([CA0s,Qs])\n",
    "\n",
    "ROOT_FOLDER=os.getcwd()\n",
    "\n",
    "##################################### MPC Parameters ######################################\n",
    "\n",
    "NUM_MPC_ITERATION=10   # MPC TOTAL ITERATION\n",
    "\n",
    "\n",
    "NUM_OUTPUTS = 2 # Number of state variables (RNN output)  \n",
    "NUM_INPUTS = 4  # Number of RNN input\n",
    "HORIZON = 2   ## MPC PREDICTION HORIZON (Depends on how many delta you want to predict with the RNN)\n",
    "\n",
    " \n",
    "NUM_IN_SEQUENCE = 10  # Number of integration time steps actually used in MPC (equal to timestep of ML model)\n",
    "\n",
    "NUM_MPC_INPUTS = 2*HORIZON  # Number of MPC inputs to be optimized, 2 is the number of control inputs \n",
    "NUM_MPC_CONSTRAINTS = HORIZON  # For each sampling time within prediction horizon, we have 1 constraint\n",
    "\n",
    "realtime_data = None\n",
    "\n",
    "setpoint=[0, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 14:49:12.896807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-04 14:49:12.897072: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-03-04 14:49:12.897116: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-03-04 14:49:12.897146: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-03-04 14:49:12.899139: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-03-04 14:49:12.899191: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-03-04 14:49:12.899214: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-03-04 14:49:12.899222: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-03-04 14:49:12.899492: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x7faeafd37bb0>\n"
     ]
    }
   ],
   "source": [
    "# define scalers for both X and y\n",
    "X_mean = np.load('X_mean.npy')\n",
    "X_std = np.load('X_std.npy')\n",
    "y_mean = np.load('y_mean.npy')\n",
    "y_std = np.load('y_std.npy')\n",
    "\n",
    "model = load_model('model.h5')\n",
    "print(model)\n",
    "\n",
    "x1_mean= X_mean[0]   # CA\n",
    "x1_std= X_std[0]\n",
    "x2_mean=X_mean[1]  # T\n",
    "x2_std= X_std[1]\n",
    "u1_mean= X_mean[2]    # CA0\n",
    "u1_std=X_std[2]\n",
    "u2_mean=X_mean[3]     # Q\n",
    "u2_std=X_std[3]\n",
    "y1_mean=y_mean[0]   # CA\n",
    "y1_std=y_std[0]\n",
    "y2_mean=y_mean[1]   # T\n",
    "y2_std=y_std[1]\n",
    "\n",
    "state_mean = np.array([x1_mean, x2_mean])  # [CA_input, T_input]\n",
    "state_std = np.array([x1_std, x2_std])\n",
    "\n",
    "input_mean = np.array([u1_mean, u2_mean])  # [CA0, Q]\n",
    "input_std = np.array([u1_std, u2_std])\n",
    "\n",
    "output_mean = np.array([y1_mean, y2_mean])  # [CA_output, T_output]\n",
    "output_std = np.array([y1_std, y2_std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_ens_prediction(num_horizon,my_rawdata,my_inputs):\n",
    "    xx = []  \n",
    "    nn_inputs = []  # NN input\n",
    "    ensemble_output = numpy.zeros((num_horizon,NUM_OUTPUTS,NUM_IN_SEQUENCE))\n",
    "    \n",
    "    ensemble_output = ensemble_output.reshape(num_horizon,NUM_IN_SEQUENCE,NUM_OUTPUTS)\n",
    "    x_test2 = my_rawdata[0:NUM_OUTPUTS].astype(float)\n",
    "    x_test2= (x_test2-state_mean)/state_std           # my_rawdata is normal value; needs to normalize before feeding into NN\n",
    "\n",
    "    predict_output_normal=[[0 for i in range(NUM_OUTPUTS)] for j in range(NUM_IN_SEQUENCE)]\n",
    "\n",
    "    for i_model in range(num_horizon):    \n",
    "  \n",
    "        # ############################# get the normalized input for RNN #########################\n",
    "         \n",
    "        my_inputs_normalized = (my_inputs[2*i_model:2*(i_model+1)] - input_mean) / input_std    # my_inputs is also normal value; needs to normalize before feeding into NN\n",
    "        xx = numpy.concatenate((x_test2,  my_inputs_normalized), axis=None).reshape((1, NUM_INPUTS))  # xx is the NN input\n",
    "        xx = numpy.tile(xx, (NUM_IN_SEQUENCE, 1))  # duplicate #NUM_IN_SEQUENCE times\n",
    "\n",
    "        nn_inputs = xx.reshape(1, NUM_IN_SEQUENCE, NUM_INPUTS) \n",
    "        # ############## use machine learning model to predict the next sampling time ##############\n",
    "        \n",
    "        predict_output = model(nn_inputs).numpy()\n",
    "        predict_output = predict_output.reshape(NUM_IN_SEQUENCE, NUM_OUTPUTS)\n",
    "        predict_output = predict_output * output_std + output_mean  # convert back to deviation form\n",
    "\n",
    "        ####################### get the system state at the end of sampling time ################\n",
    "        \n",
    "        x_test2 = predict_output[-1, :]\n",
    "\n",
    "\n",
    "        ###### transform the predicted states back to their original values in deviation form ######\n",
    "        \n",
    "        x_test2 = (x_test2 - state_mean) / state_std  # normalize input for next prediction\n",
    "\n",
    "        ensemble_output[i_model,:,:] = predict_output[:, :] # store the predicted states \n",
    "\n",
    "        ########################################################################################\n",
    "\n",
    "\n",
    "    return ensemble_output    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_f(x):\n",
    "    '''\n",
    "    define the objective function\n",
    "    '''\n",
    "    assert len(x) == int(NUM_MPC_INPUTS)\n",
    "    offset=0\n",
    "    \n",
    "    #### CALCULATE OUTLET CONC ###########\n",
    "    df_ensemble_output = my_ens_prediction(num_horizon = HORIZON, my_rawdata=realtime_data, my_inputs=x)\n",
    "\n",
    "    #### account for all intermediate steps ####\n",
    "    for j in range (HORIZON):\n",
    "        est_outlet_product = df_ensemble_output[j, :, 0:2]\n",
    "        for i in range (int(NUM_IN_SEQUENCE)):  \n",
    "           \n",
    "             offset = offset + (setpoint[0] - (est_outlet_product[i, 1])) ** 2.0  + (setpoint[1] - (est_outlet_product[i, 0])) ** 2.0 * 1000\n",
    "\n",
    "\n",
    "\n",
    "    return offset/100\n",
    "\n",
    "def eval_grad_f(x):\n",
    "    '''\n",
    "    define the gradient of the objective function\n",
    "    '''\n",
    "    assert len(x) == int(NUM_MPC_INPUTS)\n",
    "    step = 1e-1 # we just have a small step\n",
    "    objp=objm=0\n",
    "    grad_f = [0]*NUM_MPC_INPUTS\n",
    "    xpstep = [0]*NUM_MPC_INPUTS\n",
    "    xmstep = [0]*NUM_MPC_INPUTS\n",
    "    for i_mpc_input in range(NUM_MPC_INPUTS):\n",
    "        xpstep=x.copy()\n",
    "        xmstep=x.copy()\n",
    "        # for each variables, we need to evaluate the derivative of the function with respect to that variable, This is why we have the for loop\n",
    "        xpstep[i_mpc_input]  = xpstep[i_mpc_input]+step \n",
    "        xmstep[i_mpc_input] = xmstep[i_mpc_input]-step\n",
    "\n",
    "        # Evaluate the objective function at xpstep and xmstep\n",
    "        objp=eval_f(xpstep) # This function returns the value of the objective function evaluated with the variable x[i] is perturebed +step\n",
    "        objm=eval_f(xmstep) # This function returns the value of the objective function evaluated with the variable x[i] is perturebed -step\n",
    "        #print (\"obj \", objp, \"   objm   \", objm)\n",
    "        grad_f[i_mpc_input] = (objp - objm) / (2 * step) # This evaluates the gradient of the objetive function with repect to the optimization variable x[i]\n",
    "    #print(\"Gradient: \", grad_f)\n",
    "    return array(grad_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_g(x):\n",
    "    '''\n",
    "    define the constraint function\n",
    "    '''\n",
    "    assert len(x) == int(NUM_MPC_INPUTS)\n",
    "\n",
    "    CAd2=realtime_data[0]   ## current CA\n",
    "    Td2=realtime_data[1]    ## current T\n",
    "    g=array([-5.0]*NUM_MPC_CONSTRAINTS)   # g is the constraint (inequality) value; Initilize to be negative.\n",
    "\n",
    "\n",
    "    if ((a*CAd2**2+d*Td2**2+2*b*CAd2*Td2-2)> 0): # (If V > \\rho_min=2)\n",
    "        \n",
    "        df_ensemble_output3 = my_ens_prediction(num_horizon=1,my_rawdata=realtime_data, my_inputs=x)\n",
    "        \n",
    "        est_outlet = df_ensemble_output3[-1, -1, 0:2].reshape(1,2)\n",
    "        \n",
    "        # calculate the derivative of the Lyapunov function V(x,u) with respect to x\n",
    "        dot_V1=(2*a * CAd2 + 2*b * Td2)*((est_outlet[0][0])-CAd2)/(0.01)+\\\n",
    "                (2*d*Td2 + 2*b * CAd2)*((est_outlet[0][1])-Td2)/(0.01)      \n",
    "      \n",
    "\n",
    "        '''\n",
    "        This corresponds to the constraint: dot_V (x,u) < dot_V(x, \\phi(x))\n",
    "        To simplify calculation, we use the constraint, dot_V(x,u) < -15 V to make sure dot_V is negative.\n",
    "        '''\n",
    "        vv=a*CAd2**2+d*Td2**2+2*b*CAd2*Td2  # calculate the derivative of the Lyapunov function V(x,\\phi(x))\n",
    "        g[0]=dot_V1+15*abs(vv/100)   \n",
    "\n",
    "\n",
    "    else:\n",
    "        df_ensemble_output2 = my_ens_prediction(num_horizon=int(NUM_MPC_INPUTS / 2), my_rawdata=realtime_data,\n",
    "                                               my_inputs=x)\n",
    "           \n",
    "        #####  only account for the last point #####\n",
    "        for j in range(int(NUM_MPC_INPUTS / 2)):\n",
    "            est_outlet_product2 = df_ensemble_output2[j, -1, 0:2] # only account for the last point\n",
    "            \n",
    "            g[j]= d * (est_outlet_product2[1]) ** 2+ 2 * b * (est_outlet_product2[1])*(est_outlet_product2[0]) + \\\n",
    "                  a*(est_outlet_product2[0]) ** 2 -2\n",
    "            # this corresponds to the constraint: V(x,u) < 2 (\\rho_min or \\rho_nn in different papers)\n",
    "\n",
    "    return  g\n",
    "\n",
    "nnzj = NUM_MPC_CONSTRAINTS*NUM_MPC_INPUTS  ## number of nonzeros in the Jacobian of the constraint function\n",
    "\n",
    "\n",
    "def eval_jac_g(x, flag):\n",
    "    '''\n",
    "    define the Jacobian of the constraint function\n",
    "    '''\n",
    "    \n",
    "    if flag:\n",
    "        list_x = []\n",
    "        list_y=[]\n",
    "        for i in range(int(NUM_MPC_INPUTS / 2)):\n",
    "            list_x = list_x + [i] * NUM_MPC_INPUTS\n",
    "            list_y = list_y +list(range(0, int(NUM_MPC_INPUTS)))\n",
    "\n",
    "        return (array(list_x),\n",
    "                array(list_y))\n",
    "\n",
    "\n",
    "    else:\n",
    "        assert len(x) == int(NUM_MPC_INPUTS)\n",
    "        step = 1e-1 # we just have a small step\n",
    "        gp=gm=numpy.zeros(NUM_MPC_CONSTRAINTS)\n",
    "        xpstep=xmstep=numpy.zeros(NUM_MPC_INPUTS)\n",
    "        jac_g = [[0]*int(NUM_MPC_INPUTS) for _ in range(NUM_MPC_CONSTRAINTS)]\n",
    "\n",
    "        for i_mpc_input in range(NUM_MPC_INPUTS):\n",
    "            xpstep=x.copy()\n",
    "            xmstep=x.copy()\n",
    "            # for each variables, we need to evaluate the derivative of the function with respect to that variable, This is why we have the for loop\n",
    "            xpstep[i_mpc_input] += step \n",
    "            xmstep[i_mpc_input] -= step\n",
    "            gp=eval_g(xpstep)\n",
    "            gm=eval_g(xmstep)\n",
    "            for num_constraint in range(NUM_MPC_CONSTRAINTS):\n",
    "                jac_g[num_constraint][i_mpc_input] = (gp[num_constraint] - gm[num_constraint]) / (2 * step)\n",
    "            #print (\"in eval_jac_g_2:\")\n",
    "        return array(jac_g)\n",
    "\n",
    "def apply_new(x):\n",
    "    return True\n",
    "def print_variable(variable_name, value):\n",
    "    for i in range(len(value)):\n",
    "        print(\"{} {}\".format(variable_name + \"[\"+str(i)+\"] =\", value[i]))\n",
    "\n",
    "\n",
    "nnzh = NUM_MPC_INPUTS**2  ## number of nonzeros in the Hessian of the Lagrangian function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_L [-2.e+19 -2.e+19] [0 0]\n"
     ]
    }
   ],
   "source": [
    "nvar = NUM_MPC_INPUTS   ## number of variables\n",
    "x_lower=[0]* nvar   ## lower bound of the variables\n",
    "x_upper=[0]* nvar  ## upper bound of the variables  \n",
    "for i in range(int(HORIZON)):\n",
    "    x_lower[2*i]= -3.5 \n",
    "    x_lower[2 * i+1] = -5e5\n",
    "    x_upper[2 * i] = 3.5\n",
    "    x_upper[2 * i + 1] = 5e5\n",
    "x_L = array(x_lower) #array([-3.5,-5e5])\n",
    "x_U = array(x_upper) #array([3.5, 5e5])\n",
    "\n",
    "### DEFINE THE UPPER BOUND AND LOWER BOUND OF THE CONSTRAINT ###\n",
    "ncon = NUM_MPC_CONSTRAINTS      ## number of constraints\n",
    "g_L = array([-2e19]*HORIZON)    ## lower bound of the constraints\n",
    "g_U = array([0]*HORIZON)        ## upper bound of the constraints\n",
    "\n",
    "print (\"g_L\", g_L, g_U)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Iteratin:  0\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [0. 0. 0. 0.]\n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "Solution of the primal variables, x\n",
      "x[0] = 3.5000000349985347\n",
      "x[1] = -0.8601783386446912\n",
      "x[2] = 3.5000000349975773\n",
      "x[3] = -0.9449021993056471\n",
      "status= -1\n",
      "Objective value\n",
      "f(x*) = 1251.1258619520822\n",
      "Control action=:   3.5000000349985347 -0.8601783386446912\n",
      "Real model output x1 x2 in deviation form:    -1.3491245181524205 66.01608363831458\n",
      "Num Iteratin:  1\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [ 3.50000003 -0.9449022   3.50000003 -0.9449022 ]\n"
     ]
    }
   ],
   "source": [
    "for main_iteration in range(NUM_MPC_ITERATION):\n",
    "    print (\"Num Iteratin: \", main_iteration)\n",
    "\n",
    "    rawdata = numpy.array([CAi, Ti])\n",
    "    \n",
    "    realtime_data=rawdata\n",
    "\n",
    "    nlp = pyipopt.create(nvar, x_L, x_U, ncon, g_L, g_U, nnzj, nnzh, eval_f, eval_grad_f, eval_g, eval_jac_g)\n",
    "\n",
    "    if main_iteration ==0 :\n",
    "        x0 = array([0.0]*int(NUM_MPC_INPUTS))   # initial guess\n",
    "      \n",
    "    else:\n",
    "        x0=x    # use the previous solution as the initial guess\n",
    "        x0[0:-2]=x[2:]  # shift the previous solution to the left by 2\n",
    "        x0[-2:]=x[-2:]  # keep the last two elements unchanged\n",
    "        x_record=x\n",
    "\n",
    "    \"\"\"\n",
    "    print x0\n",
    "    print nvar, ncon, nnzj\n",
    "    print x_L,  x_U\n",
    "    print g_L, g_U\n",
    "    print eval_f(x0)\n",
    "    print eval_grad_f(x0)\n",
    "    print eval_g(x0)\n",
    "    a =  eval_jac_g(x0, True)\n",
    "    print \"a = \", a[1], a[0]\n",
    "    print eval_jac_g(x0, False)\n",
    "    print eval_h(x0, pi0, 1.0, False)\n",
    "    print eval_h(x0, pi0, 1.0, True)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" You CAd2 set Ipopt options by calling nlp.num_option, nlp.str_option\n",
    "    or nlp.int_option. For instance, to set the tolarance by calling\n",
    "\n",
    "        nlp.num_option('tol', 1e-8)\n",
    "\n",
    "    For a complete list of Ipopt options, refer to\n",
    "\n",
    "        http://www.coin-or.org/Ipopt/documentation/node59.html\n",
    "\n",
    "    Note that Ipopt distinguishs between Int, Num, and Str options, yet sometimes\n",
    "    does not explicitly tell you which option is which.  If you are not sure about\n",
    "    the option's type, just try it in PyIpopt.  If you try to set one type of\n",
    "    option using the wrong function, Pyipopt will remind you of it. \"\"\"\n",
    "\n",
    "    nlp.int_option('max_iter', 1000)    # maximum number of iterations\n",
    "    nlp.num_option('tol', 1e-5)         # convergence tolerance\n",
    "    nlp.int_option('print_level', 2)    # print out the process\n",
    "    print(\"Going to call solve\")        # solve the problem\n",
    "    print(\"x0 = {}\".format(x0))         # initial guess\n",
    "    x, zl, zu, constraint_multipliers, obj, status = nlp.solve(x0)  \n",
    "\n",
    "    nlp.close()\n",
    "\n",
    "    print(\"Solution of the primal variables, x\")\n",
    "    print_variable(\"x\", x)\n",
    "    print (\"status=\", status)\n",
    "\n",
    "    print(\"Objective value\")\n",
    "    print(\"f(x*) = {}\".format(obj))\n",
    "    print (\"Control action=:  \", x[0], x[1])\n",
    "\n",
    "    x1=CAi  \n",
    "    x2=Ti  \n",
    "\n",
    "    # w is the disturbance\n",
    "    # w1 =numpy.random.normal(0, w1_std, 1)\n",
    "    # w2 =numpy.random.normal(0, w2_std, 1)\n",
    "    # if w1>w1_std:\n",
    "    #     w1=w1_std\n",
    "    # if w1<-w1_std:\n",
    "    #     w1=-w1_std\n",
    "    # if w2>w2_std:\n",
    "    #     w2=w2_std\n",
    "    # if w2>w2_std:\n",
    "    #     w2=w2_std\n",
    "    #print (numpy.asscalar(w1))\n",
    "    #print (numpy.asscalar(w2))\n",
    "    for kk in range (int(delta/hc)):    # apply the control action for real model\n",
    "\n",
    "\n",
    "        x1_new = x1 + hc * ((F / V) * (x[0] - x1) -\n",
    "                            k0 * ((numpy.exp(-E / (R * (x2 + Ts)))*(x1 + CAs) * (x1 + CAs))\n",
    "                                  - numpy.exp(-E / (R * Ts)) * CAs * CAs))\n",
    "\n",
    "        x2_new = x2 + hc * (((F / V) * (-x2) + (-Dh / (sigma * cp)) *\n",
    "                             (k0 * ((numpy.exp(-E / (R * (x2 + Ts))) * (x1 + CAs) * (x1 + CAs)) -\n",
    "                                      numpy.exp(-E / (R * Ts)) * CAs * CAs)) + (x[1] / (sigma * cp * V))))\n",
    "\n",
    "\n",
    "\n",
    "        x1 = x1_new\n",
    "        x2 = x2_new\n",
    "\n",
    "        # if (kk%5==1):\n",
    "        #     x1_record.append(x1)\n",
    "        #     x2_record.append(x2)\n",
    "        #     u1_record.append(x[1])\n",
    "        #     u2_record.append(x[0])\n",
    "\n",
    "    CAi=x1\n",
    "    Ti=x2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Real model output x1 x2 in deviation form:   ', x1, x2)\n",
    "\n",
    "    x1_record.append(x1)\n",
    "    x2_record.append(x2)\n",
    "    u1_record.append(x[0])\n",
    "    u2_record.append(x[1])\n",
    "\n",
    "print (\"x1_record: \",x1_record)\n",
    "print (\"x2_record: \",x2_record)\n",
    "\n",
    "print (\"u1_record: \",u1_record)\n",
    "print (\"u2_record: \",u2_record)\n",
    "\n",
    "# numpy.savetxt(\"x1.txt\",   x1_record, fmt=\"%f\",  delimiter=\" \")\n",
    "# numpy.savetxt(\"x2.txt\",   x2_record, fmt=\"%f\",  delimiter=\" \")\n",
    "\n",
    "\n",
    "# numpy.savetxt(\"u1.txt\",   u1_record, fmt=\"%f\",  delimiter=\" \")\n",
    "# numpy.savetxt(\"u2.txt\",   u2_record, fmt=\"%f\",  delimiter=\" \")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
